{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.9.1 64-bit","metadata":{"interpreter":{"hash":"d1e546fcec3d13ed3800a66b55ad7d2a6d1a1787c6bdb47ca353dc2ffafd8db4"}}},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"colab":{"name":"prototype.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"B-xZEsvu-sty"},"source":["# Prototype to be implemented\n","## Model details\n","* **Task:** Image classification, outlier detection\n","* **Classifier:** Neural network, one-class\n","* **Feature** Subspace analysis to detect outliers\n","* **Semi-supervised**\n","\n","## Rundown of the model\n","1. Image Loading\n","2. Pre-training phase\n","    * Training with trusted training data\n","    * Supervised learning\n","3. Training phase\n","    * Training with untrusted training data\n","        * Calculating outlier score (Before backward pass)\n","        * Metrics on the test of the model\n","    * Query user on results\n","        * Determine whether data should be cleaned, removed or retained\n","    * Adjustments to the model\n","    * User feedback in the loop\n","    * Supervised by human but missing ground truth label\n","4. Stream phase (Not included in the prototype)\n","    * **Main use:** Crowdsourcing sites, streams of information etc.\n","    * Results are accessible upon user request\n","    * Extra queries to identify label flipping issues"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBtZ7oFYCk23","executionInfo":{"status":"ok","timestamp":1622506416537,"user_tz":-480,"elapsed":3018,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"028c81de-ee56-4839-e10d-6a0fcb3d29a7"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":147,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DM8DvgkfMGoY","executionInfo":{"status":"ok","timestamp":1622506418190,"user_tz":-480,"elapsed":248,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"d411f7c5-b25a-4760-c2b7-f75bbd9b1d4a"},"source":["# 0. Defining libraries and parameters\n","\n","# For plotting images\n","%matplotlib inline\n","%config InlineBackend.figure_format = \"retina\"\n","\n","import matplotlib.pyplot as plt\n","\n","# For defining torch libraries\n","import torch\n","from torch import nn, optim\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import Dataset\n","\n","# For defining custom dataset\n","from PIL import Image\n","import os, shutil, sys\n","import pickle\n","import copy\n","\n","# device\n","device = 'cpu'\n","\n","# Image size\n","size = 64\n","\n","# Helper function: outputs the metric on screen\n","def print_metrics(epoch, batch, batch_size, loss, accuracy):\n","    print('======== Metrics ========\\n\\\n","[Epoch {}]\\n \\\n","Batch {} / {}\\n \\\n","Loss = {:.5f}\\n \\\n","Accuracy = {:.2f}%'.format(epoch, batch, batch_size, loss, acc))\n","    print('=========================')\n","\n","# Helper function: flatten\n","# Flattens a nested list into a 1-D list\n","def flatten(nested_list):\n","    output = []\n","    for item in nested_list:\n","        if (type(item) == list):\n","            nested = flatten(item)\n","            for item in nested:\n","                output.append(item)\n","        else:\n","            output.append(item)\n","\n","    return output\n","\n","def get_accuracy(logits, labels):\n","    _, pred = torch.max(logits, 1)\n","    return (labels == pred).sum().item() / labels.shape[0] * 100\n","\n","###### New Dataset class to be used in 3.1 ######\n","\n","# Extending datasets.Dataset to create class UntrainedDataset\n","# Contains 2 functions for resolving label flipping and invalid data\n","class UntrustedDataset(Dataset):\n","    def __init__(self, dir, transform):\n","        self.dir = dir\n","        self.transform = transform\n","        self.data = {}\n","        self.folders = []\n","\n","        for i, val in enumerate(os.listdir(dir)):\n","            folder_path = os.path.join(dir, val)\n","            if not os.path.isfile(folder_path):\n","                self.folders.append(folder_path)\n","\n","        i = 0\n","        for f, folder in enumerate(self.folders):\n","            for val in os.listdir(folder):\n","                img_path = os.path.join(folder, val)\n","                if os.path.isfile(img_path):\n","                    _, file_extension = os.path.splitext(val)\n","                    if file_extension in ['.jpg', '.jpeg']:\n","                        self.data[i] = (img_path, f)\n","                        i += 1\n","                        # print(self.data[i])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        img_path, label = self.data[index]\n","        image = Image.open(img_path)\n","        image = self.transform(image)\n","\n","        index = torch.LongTensor([index])\n","        label = torch.LongTensor([label])\n","        return index, image, label\n","\n","    # Flips the label of the image\n","    # But does not move the image to the correct directory\n","    def flip_label(self, i, label):\n","        val = self.data[i][0]\n","        self.data[i] = (val, label)\n","\n","\n","    # Remove the invalid data by putting it in a unused directory\n","    def remove_invalid_data(self, i):\n","        self.data[i], self.data[len(self.data) - 1] = self.data[len(self.data) - 1], self.data[i]\n","        self.data.pop(len(self.data) - 1)\n","\n","print('Libraries and helper functions successfully defined')"],"execution_count":148,"outputs":[{"output_type":"stream","text":["Libraries and helper functions successfully defined\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MjCZA2MV-st3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622511213572,"user_tz":-480,"elapsed":3895,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"34b946b4-8007-4dc3-a54a-4acb4f31977e"},"source":["# 1.1 Image Loader\n","\n","# Define the data directory\n","directory = '/content/drive/MyDrive/Colab Notebooks/'\n","data_dir = os.path.join(directory, 'Cat_Dog_data/')\n","model_dir = os.path.join(directory, 'models')\n","train_data_dir = data_dir + 'train'\n","test_data_dir = data_dir + 'test'\n","untrusted_data_dir = data_dir + 'untrusted_train'\n","\n","# Define the transform to be applied on all photos\n","transform = transforms.Compose([transforms.Resize(size),\n","                                transforms.CenterCrop(size),\n","                                transforms.ToTensor()])\n","\n","# Load the directory into the ImageFolder and apply the transform\n","train_dataset = datasets.ImageFolder(train_data_dir, transform)\n","test_dataset = datasets.ImageFolder(test_data_dir, transform)\n","untrusted_dataset = UntrustedDataset(untrusted_data_dir, transform) # Note: Uses custom dataset\n","\n","# Load a batch of 32 images from dataset, the images are randomly shuffled to avoid introduction of strange artefacts\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n","untrusted_dataloader = torch.utils.data.DataLoader(untrusted_dataset, batch_size=32, shuffle=True)\n","\n","print('Dataloaders successfully initialized')\n","\n","# print(model_directory)\n","# # Test: Converting dataloader (generator) to iterator and using the function next to get the images and labels\n","# images, labels = next(iter(train_dataloader))\n","# # Display the image and permute the color channels\n","# for i in range(3):\n","#   print(labels[i])\n","#   plt.figure()\n","#   plt.imshow(images[i].permute(1,2,0))\n","#   plt.show()"],"execution_count":158,"outputs":[{"output_type":"stream","text":["Dataloaders successfully initialized\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cSAM4NsN-st7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622506430372,"user_tz":-480,"elapsed":259,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"04b3b6f3-1dd9-4d12-9cb4-81e76626c4fa"},"source":["# 1.2. Construct Model\n","\n","# model_pretrained = models.resnet18(pretrained=True)\n","\n","# The following code allows you to build a customized model\n","class BinaryClassifier(nn.Module):\n","    def __init__(self, input_size):\n","        super(BinaryClassifier, self).__init__()\n","\n","        # you can define each operator with this kind of syntax\n","        self.input_size = input_size\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2, padding=1)\n","        self.relu = nn.ReLU()\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n","        self.flatten = nn.Flatten()\n","        self.out = nn.Linear(input_size * input_size * 128 // 64, 2)\n","\n","    # x: <batch-size = N>*3*224*224 images\n","    # output: logits, N*2 vector, each value ranging from (-inf, inf)\n","    def forward(self, x):\n","      \n","        # One type, define all process one by one\n","        # this allows branching\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.conv3(x)\n","        x = self.relu(x)\n","        x = self.flatten(x)\n","        logits = self.out(x)\n","\n","        return logits\n","\n","# create the model\n","model = BinaryClassifier(input_size = size)\n","\n","###### Unused junk below ######\n","\n","# model = nn.Sequential(\n","#     nn.Conv2d(3, 64, 3, padding=1, stride=2),\n","#     nn.ReLU(),\n","#     nn.Conv2d(64, 128, 3, padding=1, stride=2),\n","#     nn.ReLU(),\n","#     nn.Flatten(),\n","#     nn.Linear(32768, 1000),\n","#     nn.ReLU(),\n","#     nn.Linear(1000,2),\n","#     nn.LogSoftmax(1)\n","# )\n","\n","# model = model_pretrained\n","\n","print('Model object successfully created')"],"execution_count":150,"outputs":[{"output_type":"stream","text":["Model object successfully created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lkpce1_t-st_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622506434295,"user_tz":-480,"elapsed":241,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"de03aa74-624d-4bae-bda1-e5910d5ad5f0"},"source":["# 1.3. Define hyperparameters\n","# Before training, we want to define the hyperparameters first\n","\n","# learning rate, if you use Adam optimizer, it is 0.01 by default\n","learn_rate = 0.001\n","# optimizer\n","optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n","\n","print('Hyperparameters successfully initialized')"],"execution_count":151,"outputs":[{"output_type":"stream","text":["Hyperparameters successfully initialized\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bUS56g57-suA"},"source":["# 2.1. Basic training loop for pretraining model\n","\n","# Pass the model to GPU\n","# if using CPU, this line has no effect\n","model = model.to(device)\n","\n","# Print the training results every 2 batches\n","print_every = 2\n","# Save the state_dict into model.pth every 2 epochs\n","save_every = 2\n","\n","# loss function, for CLASSIFICATION tasks, use cross-entropy loss\n","# if the input is logits, in range (-inf, inf), use this one\n","loss_func = nn.CrossEntropyLoss()\n","\n","# number of times to read through the entire dataset\n","num_epoch = 10\n","\n","for epoch in range(num_epoch):   \n","\n","    # this for loop iterates through the whole dataset\n","    for i, (images, labels) in enumerate(train_dataloader):\n","\n","        # plt.figure()\n","        # plt.imshow(images[0].permute(1,2,0))\n","        # plt.show()\n","\n","        # if using CPU, these two lines have no effect\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # prepare optimizer to perform model update\n","        # MUST BE CALLED BEFORE step()\n","        optimizer.zero_grad()\n","\n","        # forward pass: compute the logits (prediction)\n","        logits = model(images)\n","\n","        # print(logits)\n","        # print(labels)\n","\n","        # calculate loss, input should be (predicted, actual)\n","        loss = loss_func(logits, labels)\n","\n","        # backward pass: compute gradient and store in the model\n","        loss.backward()\n","\n","        # perform model update\n","        optimizer.step()\n","\n","        # log the progress\n","        if i % print_every == 0:\n","            _, pred = torch.max(logits, 1)\n","            acc = (labels == pred).sum().item() / images.shape[0] * 100\n","            print_metrics(epoch + 1, i + 1, len(train_dataloader), loss.item(), acc)\n","\n","    # to save the model periodically, read for torch.save()\n","    if epoch % save_every == 1:\n","        torch.save(model.state_dict(), os.path.join(model_dir, 'BinClassifier{}.pth'.format(epoch + 1)))\n","\n","print('Model is successfully trained')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVnSYkIF-suB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622508029831,"user_tz":-480,"elapsed":312,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"27211c8d-65cc-47a1-c29f-6a1d3d79ed08"},"source":["# 3.1. Define new methods to be used in next training phase\n","\n","# Determine whether the data is an outlier\n","# Input: logits, labels\n","# Output: problematic(set)\n","# If the datum has a L1 loss of larger than 0.75\n","# OR has a one-hot score > 0\n","# return the index of the datum to a set 'problematic'\n","def outlier_detector(logits, labels):\n","    \n","    threshold = 1.2\n","\n","    # L1 loss > 0.75\n","    prob = nn.functional.softmax(logits)\n","    labels = torch.nn.functional.one_hot(labels, num_classes=2)\n","    L1_loss = nn.functional.l1_loss(prob, labels, reduction='none')\n","    L1_loss = torch.sum(L1_loss, dim=-1)\n","    problematic = set(flatten((L1_loss > threshold).squeeze().nonzero().tolist()))\n","\n","    # Product of one-hot score > 0\n","    std, mean = torch.std_mean(logits)\n","    score = (logits - mean) / std\n","    indices = score[:, 0] * score[:, 1]\n","    # print(indices > 0)\n","    # print(type(problematic))\n","    problematic.update(flatten((indices > 0).squeeze().nonzero().tolist()))\n","\n","    return problematic\n","\n","# outputting the results and enabling the user to input\n","def feedback_problem_data(problem_idx, images, index, logits, labels):\n","\n","    problem_data = nn.functional.softmax(logits)[list(problem_idx)]\n","    invalid_count = []\n","\n","    for count, i in enumerate(problem_idx):\n","\n","        output_image = images[i].to(device)\n","\n","        # Show image\n","        print('Image {} / {}'.format(count+1, len(problem_idx)))\n","        plt.figure()\n","        plt.imshow(output_image.permute(1,2,0))\n","        plt.show()\n","\n","        # Prompt the user to feedback\n","        print('The model thinks that it is {0:.2f}% likely to be a cat and it is {1:.2f}% likely to be a dog.'.format(problem_data[count][0].item() * 100, problem_data[count][1].item() * 100))\n","        print('1. Cat\\t 2. Dog\\t 3. Neither')\n","\n","        feedback = 0\n","        while True:\n","            try:\n","                feedback = int(input('Please tell us what the image shows (1-3): '))\n","                if (feedback >= 1 and feedback <= 3):\n","                    break\n","            except KeyboardInterrupt:\n","                sys.exit('KeyboardInterrupt, stop running!')\n","            except:\n","                print('Invalid input, please try again.')\n","\n","\n","        # If it is either a cat or a dog, feedback the ground truth label to the model\n","        if (feedback <= 2):\n","            feedback -= 1\n","            gt_label = torch.tensor(feedback)\n","            if labels[i].item() != gt_label.item():\n","                  untrusted_dataset.flip_label(index[i].item(), gt_label)\n","\n","        # If it is neither, then it is an invalid data, remove it from training!\n","        if (feedback == 3):\n","            untrusted_dataset.remove_invalid_data(index[i].item())\n","            invalid_count.append(i)\n","\n","    problem_idx = problem_idx.difference(invalid_count)\n","\n","    return problem_idx\n","\n","print('Helper functions are successfully defined')"],"execution_count":155,"outputs":[{"output_type":"stream","text":["Helper functions are successfully defined\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DRkovltLsQGr","executionInfo":{"status":"ok","timestamp":1622512255913,"user_tz":-480,"elapsed":1017628,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"2fccb995-0f30-4e96-a36e-8ab71ba06698"},"source":["# 3.2. Training under human supervision\n","# Some of the data here is unclean, and there is no ground-truth label provided\n","# However, the human serves as an input to provide feedback for the model\n","\n","# Loading the trained model from last phase\n","model_path = os.path.join(model_dir, 'BinClassifier8.pth')\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model = model.to(device)\n","\n","# Define loss function\n","loss_func = nn.CrossEntropyLoss(reduction='none')\n","\n","# Saving the model every 2 epochs\n","save_every = 1\n","num_epoch = 10\n","train_epoch = 0\n","print_every = 10\n","feedback_every = 8\n","\n","for epoch in range(num_epoch):\n","\n","    # Redefine the dataloader after removing photos\n","    # Utilize the deep copy of the dataset to load images\n","    temp = copy.deepcopy(untrusted_dataset)\n","    untrusted_dataloader = torch.utils.data.DataLoader(temp, batch_size=32, shuffle=True)\n","\n","    # this for loop iterates through the whole dataset\n","    for i, (index, images, labels) in enumerate(untrusted_dataloader):\n","\n","        batch_size = images.shape[0]\n","        index = index.squeeze()\n","        labels = labels.squeeze()\n","\n","        # if using CPU, these two lines have no effect\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # prepare optimizer to perform model update\n","        # MUST BE CALLED BEFORE step()\n","        optimizer.zero_grad()\n","\n","        # forward pass: compute the logits (prediction)\n","        logits = model(images)\n","\n","        if epoch < train_epoch and i % feedback_every == 0:\n","            # Check for any outliers right here using outlier_detector(logits, labels)\n","            problem_idx = outlier_detector(logits, labels)\n","            # print(problem_idx)\n","        else:\n","            problem_idx = set()\n","\n","        # calculate loss, input should be (predicted, actual)\n","        loss = loss_func(logits, labels) # 32 * 1 tensor\n","\n","        # Set loss of prob_idx to 0\n","        loss[list(problem_idx)] = torch.zeros(1).to(device)\n","\n","        # Divide by the num of clean data, then sum then up\n","        loss = loss / (images.shape[0] - len(problem_idx))\n","        loss = torch.sum(loss)\n","\n","        # backward pass: compute gradient and store in the model\n","        loss.backward()\n","\n","        # perform model update\n","        optimizer.step()\n","\n","        if epoch < train_epoch and i % feedback_every == 0:\n","\n","            if len(problem_idx) > 0:\n","\n","                # Log the progress\n","                # created Boolean mask to filter the problematic data\n","                problem_idx_bool_tensor = torch.ones(batch_size, dtype=torch.bool)\n","                problem_idx_bool_tensor[list(problem_idx)] = False\n","\n","                trimmed_logits = torch.Tensor(batch_size - len(problem_idx), 2).to(device)\n","                trimmed_logits[:,0] = torch.masked_select(logits[:,0], problem_idx_bool_tensor)\n","                trimmed_logits[:,1] = torch.masked_select(logits[:,1], problem_idx_bool_tensor)\n","\n","                # print(trimmed_logits)\n","                _, pred = torch.max(trimmed_logits, 1)\n","                # print(pred)\n","                # print(torch.masked_select(labels, problem_idx_bool_tensor))\n","                batch_correct = (torch.masked_select(labels, problem_idx_bool_tensor) == pred).sum().item()\n","                batch_num = images.shape[0] - len(problem_idx)\n","                batch_acc = batch_correct / batch_num * 100\n","                print_metrics(epoch + 1, i + 1, len(untrusted_dataloader), loss.item(), batch_acc)\n","\n","                # Output the data to the human user\n","                problem_idx = feedback_problem_data(problem_idx, images, index, logits, labels)\n","\n","            else:\n","                print('This batch contains no problematic data :)')\n","                entire_batch_acc = get_accuracy(logits, labels)\n","                acc = (entire_batch_acc + acc * i) / (i + 1)\n","                print_metrics(epoch + 1, i + 1, len(untrusted_dataloader), loss.item(), acc)\n","                continue\n","\n","            \n","            if len(problem_idx) > 0:\n","                # train the model with the fixed labels (if the data is valid)\n","                fixed_images = images[list(problem_idx)]\n","                fixed_labels = labels[list(problem_idx)]\n","\n","                fixed_logits = model(fixed_images)\n","\n","                loss = loss_func(fixed_logits, fixed_labels)\n","                loss = torch.mean(loss)\n","\n","                loss.backward()\n","\n","                optimizer.step()\n","\n","                # Calculate the accuracy\n","                _, fixed_pred = torch.max(fixed_logits, 1)\n","                fixed_correct = (fixed_labels == fixed_pred).sum().item()\n","                # batch_acc = fixed_correct / fixed_images.shape[0] * 100\n","                \n","                entire_batch_acc = (batch_correct + fixed_correct) / (batch_num + fixed_images.shape[0]) * 100\n","                acc = (entire_batch_acc + acc * i) / (i + 1)\n","                \n","                print('====== After feedback ======')\n","                print_metrics(epoch + 1, i + 1, len(untrusted_dataloader), loss.item(), acc)\n","\n","            else:\n","                entire_batch_acc = batch_acc\n","                acc = (entire_batch_acc + acc * i) / (i + 1)\n","                print('This batch has no more data to train!')\n","                print_metrics(epoch + 1, i + 1, len(untrusted_dataloader), loss.item(), acc)\n","\n","        else:\n","            entire_batch_acc = get_accuracy(logits, labels)\n","            acc = (entire_batch_acc + acc * i) / (i + 1)\n","            if i % print_every == 0:\n","                print_metrics(epoch + 1, i + 1, len(untrusted_dataloader), loss.item(), acc)\n","\n","\n","    # to save the model periodically, read for torch.save()\n","    if epoch % save_every == 0:\n","        torch.save(model.state_dict(), os.path.join(model_dir, 'Control_BinClassifier{}.pth'.format(epoch + 1)))\n","        if train_epoch > 0:\n","            with open(os.path.join(directory, 'CleanedDataset3'),'wb') as filehandler:\n","                pickle.dump(untrusted_dataset, filehandler)\n","            \n","print('Model is successfully trained')"],"execution_count":159,"outputs":[{"output_type":"stream","text":["======== Metrics ========\n","[Epoch 1]\n"," Batch 1 / 461\n"," Loss = 0.96505\n"," Accuracy = 56.25%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 11 / 461\n"," Loss = 0.81899\n"," Accuracy = 67.05%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 21 / 461\n"," Loss = 0.61421\n"," Accuracy = 68.60%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 31 / 461\n"," Loss = 0.65720\n"," Accuracy = 67.44%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 41 / 461\n"," Loss = 0.84204\n"," Accuracy = 67.23%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 51 / 461\n"," Loss = 0.66352\n"," Accuracy = 67.89%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 61 / 461\n"," Loss = 0.56078\n"," Accuracy = 67.88%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 71 / 461\n"," Loss = 0.59619\n"," Accuracy = 67.91%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 81 / 461\n"," Loss = 0.60725\n"," Accuracy = 67.94%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 91 / 461\n"," Loss = 0.59745\n"," Accuracy = 68.17%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 101 / 461\n"," Loss = 0.48832\n"," Accuracy = 68.35%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 111 / 461\n"," Loss = 0.58184\n"," Accuracy = 68.30%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 121 / 461\n"," Loss = 0.55484\n"," Accuracy = 68.49%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 131 / 461\n"," Loss = 0.59610\n"," Accuracy = 68.46%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 141 / 461\n"," Loss = 0.55963\n"," Accuracy = 68.68%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 151 / 461\n"," Loss = 0.55844\n"," Accuracy = 68.89%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 161 / 461\n"," Loss = 0.56456\n"," Accuracy = 68.75%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 171 / 461\n"," Loss = 0.66336\n"," Accuracy = 68.49%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 181 / 461\n"," Loss = 0.59418\n"," Accuracy = 68.51%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 191 / 461\n"," Loss = 0.48220\n"," Accuracy = 68.57%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 201 / 461\n"," Loss = 0.67303\n"," Accuracy = 68.61%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 211 / 461\n"," Loss = 0.59605\n"," Accuracy = 68.48%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 221 / 461\n"," Loss = 0.53251\n"," Accuracy = 68.42%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 231 / 461\n"," Loss = 0.56696\n"," Accuracy = 68.47%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 241 / 461\n"," Loss = 0.60519\n"," Accuracy = 68.39%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 251 / 461\n"," Loss = 0.53555\n"," Accuracy = 68.56%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 261 / 461\n"," Loss = 0.65431\n"," Accuracy = 68.77%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 271 / 461\n"," Loss = 0.58190\n"," Accuracy = 68.88%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 281 / 461\n"," Loss = 0.74527\n"," Accuracy = 68.73%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 291 / 461\n"," Loss = 0.48925\n"," Accuracy = 68.71%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 301 / 461\n"," Loss = 0.64358\n"," Accuracy = 68.49%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 311 / 461\n"," Loss = 0.46628\n"," Accuracy = 68.58%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 321 / 461\n"," Loss = 0.64748\n"," Accuracy = 68.61%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 331 / 461\n"," Loss = 0.54405\n"," Accuracy = 68.65%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 341 / 461\n"," Loss = 0.63823\n"," Accuracy = 68.56%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 351 / 461\n"," Loss = 0.52164\n"," Accuracy = 68.56%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 361 / 461\n"," Loss = 0.40599\n"," Accuracy = 68.75%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 371 / 461\n"," Loss = 0.64266\n"," Accuracy = 68.83%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 381 / 461\n"," Loss = 0.56055\n"," Accuracy = 68.90%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 391 / 461\n"," Loss = 0.49388\n"," Accuracy = 68.89%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 401 / 461\n"," Loss = 0.45980\n"," Accuracy = 68.87%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 411 / 461\n"," Loss = 0.57294\n"," Accuracy = 68.90%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 421 / 461\n"," Loss = 0.47065\n"," Accuracy = 69.02%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 431 / 461\n"," Loss = 0.57372\n"," Accuracy = 68.97%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 441 / 461\n"," Loss = 0.50996\n"," Accuracy = 69.09%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 451 / 461\n"," Loss = 0.39379\n"," Accuracy = 69.10%\n","=========================\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 461 / 461\n"," Loss = 0.58496\n"," Accuracy = 69.23%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 1 / 461\n"," Loss = 0.55574\n"," Accuracy = 75.00%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 11 / 461\n"," Loss = 0.45758\n"," Accuracy = 71.59%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 21 / 461\n"," Loss = 0.60855\n"," Accuracy = 73.51%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 31 / 461\n"," Loss = 0.44649\n"," Accuracy = 72.68%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 41 / 461\n"," Loss = 0.48575\n"," Accuracy = 74.16%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 51 / 461\n"," Loss = 0.60475\n"," Accuracy = 73.41%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 61 / 461\n"," Loss = 0.50386\n"," Accuracy = 72.49%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 71 / 461\n"," Loss = 0.57703\n"," Accuracy = 72.36%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 81 / 461\n"," Loss = 0.53576\n"," Accuracy = 72.72%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 91 / 461\n"," Loss = 0.58506\n"," Accuracy = 72.53%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 101 / 461\n"," Loss = 0.52159\n"," Accuracy = 72.56%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 111 / 461\n"," Loss = 0.57099\n"," Accuracy = 72.33%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 121 / 461\n"," Loss = 0.61628\n"," Accuracy = 72.37%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 131 / 461\n"," Loss = 0.55153\n"," Accuracy = 72.33%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 141 / 461\n"," Loss = 0.51134\n"," Accuracy = 72.50%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 151 / 461\n"," Loss = 0.51682\n"," Accuracy = 72.39%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 161 / 461\n"," Loss = 0.65930\n"," Accuracy = 72.24%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 171 / 461\n"," Loss = 0.52511\n"," Accuracy = 72.24%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 181 / 461\n"," Loss = 0.58476\n"," Accuracy = 72.20%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 191 / 461\n"," Loss = 0.62263\n"," Accuracy = 71.99%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 201 / 461\n"," Loss = 0.65342\n"," Accuracy = 72.03%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 211 / 461\n"," Loss = 0.53187\n"," Accuracy = 72.02%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 221 / 461\n"," Loss = 0.49467\n"," Accuracy = 72.12%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 231 / 461\n"," Loss = 0.62358\n"," Accuracy = 72.02%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 241 / 461\n"," Loss = 0.59943\n"," Accuracy = 72.25%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 251 / 461\n"," Loss = 0.55474\n"," Accuracy = 72.41%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 261 / 461\n"," Loss = 0.46599\n"," Accuracy = 72.40%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 271 / 461\n"," Loss = 0.60716\n"," Accuracy = 72.24%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 281 / 461\n"," Loss = 0.45998\n"," Accuracy = 72.19%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 291 / 461\n"," Loss = 0.55169\n"," Accuracy = 72.23%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 301 / 461\n"," Loss = 0.54948\n"," Accuracy = 72.23%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 311 / 461\n"," Loss = 0.64137\n"," Accuracy = 72.26%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 321 / 461\n"," Loss = 0.60902\n"," Accuracy = 72.17%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 331 / 461\n"," Loss = 0.67325\n"," Accuracy = 72.14%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 341 / 461\n"," Loss = 0.56414\n"," Accuracy = 72.22%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 351 / 461\n"," Loss = 0.58396\n"," Accuracy = 72.29%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 361 / 461\n"," Loss = 0.46648\n"," Accuracy = 72.39%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 371 / 461\n"," Loss = 0.46384\n"," Accuracy = 72.50%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 381 / 461\n"," Loss = 0.37707\n"," Accuracy = 72.48%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 391 / 461\n"," Loss = 0.68269\n"," Accuracy = 72.60%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 401 / 461\n"," Loss = 0.62360\n"," Accuracy = 72.51%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 411 / 461\n"," Loss = 0.58389\n"," Accuracy = 72.44%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 421 / 461\n"," Loss = 0.57060\n"," Accuracy = 72.50%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 431 / 461\n"," Loss = 0.67404\n"," Accuracy = 72.40%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 441 / 461\n"," Loss = 0.36769\n"," Accuracy = 72.40%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 451 / 461\n"," Loss = 0.51815\n"," Accuracy = 72.31%\n","=========================\n","======== Metrics ========\n","[Epoch 2]\n"," Batch 461 / 461\n"," Loss = 0.48843\n"," Accuracy = 72.30%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 1 / 461\n"," Loss = 0.63365\n"," Accuracy = 65.62%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 11 / 461\n"," Loss = 0.56024\n"," Accuracy = 73.30%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 21 / 461\n"," Loss = 0.41482\n"," Accuracy = 74.40%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 31 / 461\n"," Loss = 0.55291\n"," Accuracy = 74.80%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 41 / 461\n"," Loss = 0.63138\n"," Accuracy = 73.48%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 51 / 461\n"," Loss = 0.33793\n"," Accuracy = 73.22%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 61 / 461\n"," Loss = 0.56395\n"," Accuracy = 72.80%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 71 / 461\n"," Loss = 0.55198\n"," Accuracy = 73.06%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 81 / 461\n"," Loss = 0.67676\n"," Accuracy = 72.69%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 91 / 461\n"," Loss = 0.46930\n"," Accuracy = 72.97%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 101 / 461\n"," Loss = 0.53334\n"," Accuracy = 73.14%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 111 / 461\n"," Loss = 0.42989\n"," Accuracy = 73.25%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 121 / 461\n"," Loss = 0.46381\n"," Accuracy = 73.30%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 131 / 461\n"," Loss = 0.35177\n"," Accuracy = 73.62%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 141 / 461\n"," Loss = 0.66127\n"," Accuracy = 73.36%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 151 / 461\n"," Loss = 0.52951\n"," Accuracy = 73.53%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 161 / 461\n"," Loss = 0.39205\n"," Accuracy = 73.66%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 171 / 461\n"," Loss = 0.48322\n"," Accuracy = 73.89%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 181 / 461\n"," Loss = 0.62072\n"," Accuracy = 73.76%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 191 / 461\n"," Loss = 0.54769\n"," Accuracy = 73.58%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 201 / 461\n"," Loss = 0.65102\n"," Accuracy = 73.41%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 211 / 461\n"," Loss = 0.39971\n"," Accuracy = 73.40%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 221 / 461\n"," Loss = 0.45153\n"," Accuracy = 73.42%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 231 / 461\n"," Loss = 0.37443\n"," Accuracy = 73.58%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 241 / 461\n"," Loss = 0.53185\n"," Accuracy = 73.66%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 251 / 461\n"," Loss = 0.69026\n"," Accuracy = 73.71%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 261 / 461\n"," Loss = 0.45467\n"," Accuracy = 73.71%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 271 / 461\n"," Loss = 0.66602\n"," Accuracy = 73.60%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 281 / 461\n"," Loss = 0.58737\n"," Accuracy = 73.60%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 291 / 461\n"," Loss = 0.51775\n"," Accuracy = 73.71%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 301 / 461\n"," Loss = 0.46362\n"," Accuracy = 73.71%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 311 / 461\n"," Loss = 0.38585\n"," Accuracy = 73.72%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 321 / 461\n"," Loss = 0.63737\n"," Accuracy = 73.68%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 331 / 461\n"," Loss = 0.48486\n"," Accuracy = 73.70%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 341 / 461\n"," Loss = 0.49580\n"," Accuracy = 73.63%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 351 / 461\n"," Loss = 0.52174\n"," Accuracy = 73.78%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 361 / 461\n"," Loss = 0.49427\n"," Accuracy = 73.85%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 371 / 461\n"," Loss = 0.47244\n"," Accuracy = 73.74%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 381 / 461\n"," Loss = 0.67535\n"," Accuracy = 73.74%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 391 / 461\n"," Loss = 0.45111\n"," Accuracy = 73.81%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 401 / 461\n"," Loss = 0.50157\n"," Accuracy = 73.76%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 411 / 461\n"," Loss = 0.54438\n"," Accuracy = 73.76%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 421 / 461\n"," Loss = 0.49345\n"," Accuracy = 73.69%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 431 / 461\n"," Loss = 0.56480\n"," Accuracy = 73.62%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 441 / 461\n"," Loss = 0.47843\n"," Accuracy = 73.71%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 451 / 461\n"," Loss = 0.64188\n"," Accuracy = 73.70%\n","=========================\n","======== Metrics ========\n","[Epoch 3]\n"," Batch 461 / 461\n"," Loss = 0.33226\n"," Accuracy = 73.73%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 1 / 461\n"," Loss = 0.51157\n"," Accuracy = 75.00%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 11 / 461\n"," Loss = 0.45342\n"," Accuracy = 77.27%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 21 / 461\n"," Loss = 0.52504\n"," Accuracy = 76.64%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 31 / 461\n"," Loss = 0.36934\n"," Accuracy = 77.32%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 41 / 461\n"," Loss = 0.53853\n"," Accuracy = 76.45%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 51 / 461\n"," Loss = 0.54285\n"," Accuracy = 76.41%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 61 / 461\n"," Loss = 0.53779\n"," Accuracy = 76.43%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 71 / 461\n"," Loss = 0.48426\n"," Accuracy = 76.28%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 81 / 461\n"," Loss = 0.57409\n"," Accuracy = 76.54%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 91 / 461\n"," Loss = 0.41216\n"," Accuracy = 76.79%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 101 / 461\n"," Loss = 0.43429\n"," Accuracy = 77.04%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 111 / 461\n"," Loss = 0.52926\n"," Accuracy = 77.14%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 121 / 461\n"," Loss = 0.48330\n"," Accuracy = 77.30%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 131 / 461\n"," Loss = 0.61087\n"," Accuracy = 76.84%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 141 / 461\n"," Loss = 0.42226\n"," Accuracy = 76.53%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 151 / 461\n"," Loss = 0.51348\n"," Accuracy = 76.35%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 161 / 461\n"," Loss = 0.48186\n"," Accuracy = 76.34%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 171 / 461\n"," Loss = 0.54926\n"," Accuracy = 76.39%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 181 / 461\n"," Loss = 0.47946\n"," Accuracy = 76.21%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 191 / 461\n"," Loss = 0.51503\n"," Accuracy = 76.24%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 201 / 461\n"," Loss = 0.49828\n"," Accuracy = 76.20%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 211 / 461\n"," Loss = 0.60691\n"," Accuracy = 76.07%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 221 / 461\n"," Loss = 0.43234\n"," Accuracy = 76.20%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 231 / 461\n"," Loss = 0.44322\n"," Accuracy = 76.22%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 241 / 461\n"," Loss = 0.56371\n"," Accuracy = 76.15%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 251 / 461\n"," Loss = 0.46481\n"," Accuracy = 76.08%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 261 / 461\n"," Loss = 0.58273\n"," Accuracy = 76.05%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 271 / 461\n"," Loss = 0.38268\n"," Accuracy = 76.13%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 281 / 461\n"," Loss = 0.48134\n"," Accuracy = 76.03%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 291 / 461\n"," Loss = 0.45258\n"," Accuracy = 75.96%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 301 / 461\n"," Loss = 0.52943\n"," Accuracy = 75.85%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 311 / 461\n"," Loss = 0.60602\n"," Accuracy = 75.81%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 321 / 461\n"," Loss = 0.46543\n"," Accuracy = 75.76%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 331 / 461\n"," Loss = 0.72235\n"," Accuracy = 75.86%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 341 / 461\n"," Loss = 0.53963\n"," Accuracy = 75.79%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 351 / 461\n"," Loss = 0.45265\n"," Accuracy = 75.68%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 361 / 461\n"," Loss = 0.59399\n"," Accuracy = 75.58%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 371 / 461\n"," Loss = 0.38293\n"," Accuracy = 75.73%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 381 / 461\n"," Loss = 0.43870\n"," Accuracy = 75.67%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 391 / 461\n"," Loss = 0.56255\n"," Accuracy = 75.63%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 401 / 461\n"," Loss = 0.57089\n"," Accuracy = 75.65%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 411 / 461\n"," Loss = 0.56185\n"," Accuracy = 75.69%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 421 / 461\n"," Loss = 0.50128\n"," Accuracy = 75.68%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 431 / 461\n"," Loss = 0.38199\n"," Accuracy = 75.67%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 441 / 461\n"," Loss = 0.57603\n"," Accuracy = 75.65%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 451 / 461\n"," Loss = 0.35916\n"," Accuracy = 75.64%\n","=========================\n","======== Metrics ========\n","[Epoch 4]\n"," Batch 461 / 461\n"," Loss = 0.64166\n"," Accuracy = 75.56%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 1 / 461\n"," Loss = 0.50513\n"," Accuracy = 65.62%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 11 / 461\n"," Loss = 0.45873\n"," Accuracy = 76.99%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 21 / 461\n"," Loss = 0.44629\n"," Accuracy = 78.57%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 31 / 461\n"," Loss = 0.31559\n"," Accuracy = 77.82%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 41 / 461\n"," Loss = 0.39448\n"," Accuracy = 77.82%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 51 / 461\n"," Loss = 0.37101\n"," Accuracy = 78.74%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 61 / 461\n"," Loss = 0.45114\n"," Accuracy = 78.12%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 71 / 461\n"," Loss = 0.37742\n"," Accuracy = 78.08%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 81 / 461\n"," Loss = 0.50298\n"," Accuracy = 77.93%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 91 / 461\n"," Loss = 0.55105\n"," Accuracy = 77.99%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 101 / 461\n"," Loss = 0.37751\n"," Accuracy = 77.85%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 111 / 461\n"," Loss = 0.47383\n"," Accuracy = 77.96%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 121 / 461\n"," Loss = 0.59026\n"," Accuracy = 77.92%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 131 / 461\n"," Loss = 0.43978\n"," Accuracy = 77.98%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 141 / 461\n"," Loss = 0.51506\n"," Accuracy = 77.88%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 151 / 461\n"," Loss = 0.70490\n"," Accuracy = 77.69%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 161 / 461\n"," Loss = 0.45730\n"," Accuracy = 77.54%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 171 / 461\n"," Loss = 0.37924\n"," Accuracy = 77.80%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 181 / 461\n"," Loss = 0.57496\n"," Accuracy = 77.76%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 191 / 461\n"," Loss = 0.47901\n"," Accuracy = 77.78%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 201 / 461\n"," Loss = 0.41253\n"," Accuracy = 77.83%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 211 / 461\n"," Loss = 0.44043\n"," Accuracy = 77.90%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 221 / 461\n"," Loss = 0.63495\n"," Accuracy = 77.81%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 231 / 461\n"," Loss = 0.42150\n"," Accuracy = 77.91%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 241 / 461\n"," Loss = 0.63794\n"," Accuracy = 77.87%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 251 / 461\n"," Loss = 0.47115\n"," Accuracy = 77.64%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 261 / 461\n"," Loss = 0.42653\n"," Accuracy = 77.62%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 271 / 461\n"," Loss = 0.55428\n"," Accuracy = 77.57%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 281 / 461\n"," Loss = 0.39222\n"," Accuracy = 77.56%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 291 / 461\n"," Loss = 0.43239\n"," Accuracy = 77.64%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 301 / 461\n"," Loss = 0.56406\n"," Accuracy = 77.56%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 311 / 461\n"," Loss = 0.36051\n"," Accuracy = 77.49%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 321 / 461\n"," Loss = 0.51219\n"," Accuracy = 77.37%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 331 / 461\n"," Loss = 0.43234\n"," Accuracy = 77.39%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 341 / 461\n"," Loss = 0.52389\n"," Accuracy = 77.44%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 351 / 461\n"," Loss = 0.51544\n"," Accuracy = 77.39%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 361 / 461\n"," Loss = 0.55466\n"," Accuracy = 77.46%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 371 / 461\n"," Loss = 0.52975\n"," Accuracy = 77.39%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 381 / 461\n"," Loss = 0.56228\n"," Accuracy = 77.31%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 391 / 461\n"," Loss = 0.45260\n"," Accuracy = 77.37%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 401 / 461\n"," Loss = 0.38667\n"," Accuracy = 77.45%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 411 / 461\n"," Loss = 0.49241\n"," Accuracy = 77.43%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 421 / 461\n"," Loss = 0.37835\n"," Accuracy = 77.35%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 431 / 461\n"," Loss = 0.41675\n"," Accuracy = 77.36%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 441 / 461\n"," Loss = 0.59228\n"," Accuracy = 77.25%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 451 / 461\n"," Loss = 0.41214\n"," Accuracy = 77.20%\n","=========================\n","======== Metrics ========\n","[Epoch 5]\n"," Batch 461 / 461\n"," Loss = 0.41283\n"," Accuracy = 77.17%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 1 / 461\n"," Loss = 0.35900\n"," Accuracy = 90.62%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 11 / 461\n"," Loss = 0.44647\n"," Accuracy = 78.98%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 21 / 461\n"," Loss = 0.37958\n"," Accuracy = 80.80%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 31 / 461\n"," Loss = 0.46315\n"," Accuracy = 80.34%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 41 / 461\n"," Loss = 0.40267\n"," Accuracy = 79.80%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 51 / 461\n"," Loss = 0.37623\n"," Accuracy = 80.02%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 61 / 461\n"," Loss = 0.39541\n"," Accuracy = 80.33%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 71 / 461\n"," Loss = 0.57340\n"," Accuracy = 80.37%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 81 / 461\n"," Loss = 0.45599\n"," Accuracy = 80.25%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 91 / 461\n"," Loss = 0.45257\n"," Accuracy = 80.01%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 101 / 461\n"," Loss = 0.54064\n"," Accuracy = 79.83%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 111 / 461\n"," Loss = 0.35182\n"," Accuracy = 79.70%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 121 / 461\n"," Loss = 0.41238\n"," Accuracy = 79.65%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 131 / 461\n"," Loss = 0.42459\n"," Accuracy = 79.58%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 141 / 461\n"," Loss = 0.35664\n"," Accuracy = 79.77%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 151 / 461\n"," Loss = 0.46051\n"," Accuracy = 79.55%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 161 / 461\n"," Loss = 0.45690\n"," Accuracy = 79.54%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 171 / 461\n"," Loss = 0.62806\n"," Accuracy = 79.31%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 181 / 461\n"," Loss = 0.60491\n"," Accuracy = 79.39%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 191 / 461\n"," Loss = 0.38085\n"," Accuracy = 79.25%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 201 / 461\n"," Loss = 0.42545\n"," Accuracy = 79.18%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 211 / 461\n"," Loss = 0.37596\n"," Accuracy = 79.16%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 221 / 461\n"," Loss = 0.45987\n"," Accuracy = 79.21%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 231 / 461\n"," Loss = 0.45893\n"," Accuracy = 79.26%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 241 / 461\n"," Loss = 0.30658\n"," Accuracy = 79.34%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 251 / 461\n"," Loss = 0.53042\n"," Accuracy = 79.42%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 261 / 461\n"," Loss = 0.42976\n"," Accuracy = 79.44%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 271 / 461\n"," Loss = 0.43123\n"," Accuracy = 79.39%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 281 / 461\n"," Loss = 0.44945\n"," Accuracy = 79.44%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 291 / 461\n"," Loss = 0.32348\n"," Accuracy = 79.38%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 301 / 461\n"," Loss = 0.56560\n"," Accuracy = 79.25%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 311 / 461\n"," Loss = 0.31761\n"," Accuracy = 79.23%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 321 / 461\n"," Loss = 0.37743\n"," Accuracy = 79.23%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 331 / 461\n"," Loss = 0.64919\n"," Accuracy = 79.25%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 341 / 461\n"," Loss = 0.42108\n"," Accuracy = 79.22%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 351 / 461\n"," Loss = 0.47382\n"," Accuracy = 79.25%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 361 / 461\n"," Loss = 0.41934\n"," Accuracy = 79.25%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 371 / 461\n"," Loss = 0.49155\n"," Accuracy = 79.19%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 381 / 461\n"," Loss = 0.27137\n"," Accuracy = 79.18%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 391 / 461\n"," Loss = 0.48259\n"," Accuracy = 79.11%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 401 / 461\n"," Loss = 0.37927\n"," Accuracy = 79.14%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 411 / 461\n"," Loss = 0.59902\n"," Accuracy = 79.17%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 421 / 461\n"," Loss = 0.35099\n"," Accuracy = 79.19%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 431 / 461\n"," Loss = 0.34445\n"," Accuracy = 79.17%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 441 / 461\n"," Loss = 0.39026\n"," Accuracy = 79.16%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 451 / 461\n"," Loss = 0.50468\n"," Accuracy = 79.09%\n","=========================\n","======== Metrics ========\n","[Epoch 6]\n"," Batch 461 / 461\n"," Loss = 0.28644\n"," Accuracy = 79.11%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 1 / 461\n"," Loss = 0.44532\n"," Accuracy = 71.88%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 11 / 461\n"," Loss = 0.39730\n"," Accuracy = 83.81%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 21 / 461\n"," Loss = 0.38683\n"," Accuracy = 82.89%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 31 / 461\n"," Loss = 0.47026\n"," Accuracy = 82.56%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 41 / 461\n"," Loss = 0.40755\n"," Accuracy = 82.70%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 51 / 461\n"," Loss = 0.25688\n"," Accuracy = 83.09%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 61 / 461\n"," Loss = 0.66897\n"," Accuracy = 82.12%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 71 / 461\n"," Loss = 0.36515\n"," Accuracy = 82.61%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 81 / 461\n"," Loss = 0.32498\n"," Accuracy = 82.41%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 91 / 461\n"," Loss = 0.35832\n"," Accuracy = 82.55%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 101 / 461\n"," Loss = 0.28638\n"," Accuracy = 82.49%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 111 / 461\n"," Loss = 0.55750\n"," Accuracy = 82.46%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 121 / 461\n"," Loss = 0.42178\n"," Accuracy = 82.28%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 131 / 461\n"," Loss = 0.30612\n"," Accuracy = 82.32%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 141 / 461\n"," Loss = 0.42980\n"," Accuracy = 82.00%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 151 / 461\n"," Loss = 0.27342\n"," Accuracy = 82.24%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 161 / 461\n"," Loss = 0.30413\n"," Accuracy = 82.30%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 171 / 461\n"," Loss = 0.41226\n"," Accuracy = 82.22%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 181 / 461\n"," Loss = 0.30771\n"," Accuracy = 82.17%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 191 / 461\n"," Loss = 0.47113\n"," Accuracy = 82.17%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 201 / 461\n"," Loss = 0.31439\n"," Accuracy = 82.14%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 211 / 461\n"," Loss = 0.36782\n"," Accuracy = 82.05%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 221 / 461\n"," Loss = 0.48464\n"," Accuracy = 82.06%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 231 / 461\n"," Loss = 0.41385\n"," Accuracy = 81.94%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 241 / 461\n"," Loss = 0.44601\n"," Accuracy = 82.00%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 251 / 461\n"," Loss = 0.61587\n"," Accuracy = 81.98%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 261 / 461\n"," Loss = 0.56361\n"," Accuracy = 81.91%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 271 / 461\n"," Loss = 0.37981\n"," Accuracy = 81.95%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 281 / 461\n"," Loss = 0.47875\n"," Accuracy = 81.84%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 291 / 461\n"," Loss = 0.39871\n"," Accuracy = 81.79%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 301 / 461\n"," Loss = 0.35104\n"," Accuracy = 81.74%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 311 / 461\n"," Loss = 0.41857\n"," Accuracy = 81.90%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 321 / 461\n"," Loss = 0.40361\n"," Accuracy = 81.93%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 331 / 461\n"," Loss = 0.28118\n"," Accuracy = 81.99%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 341 / 461\n"," Loss = 0.42216\n"," Accuracy = 81.95%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 351 / 461\n"," Loss = 0.44873\n"," Accuracy = 81.94%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 361 / 461\n"," Loss = 0.42468\n"," Accuracy = 81.91%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 371 / 461\n"," Loss = 0.52745\n"," Accuracy = 81.96%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 381 / 461\n"," Loss = 0.48424\n"," Accuracy = 81.84%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 391 / 461\n"," Loss = 0.47431\n"," Accuracy = 81.85%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 401 / 461\n"," Loss = 0.23000\n"," Accuracy = 81.84%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 411 / 461\n"," Loss = 0.40839\n"," Accuracy = 81.81%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 421 / 461\n"," Loss = 0.32642\n"," Accuracy = 81.76%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 431 / 461\n"," Loss = 0.52818\n"," Accuracy = 81.76%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 441 / 461\n"," Loss = 0.34743\n"," Accuracy = 81.79%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 451 / 461\n"," Loss = 0.44957\n"," Accuracy = 81.69%\n","=========================\n","======== Metrics ========\n","[Epoch 7]\n"," Batch 461 / 461\n"," Loss = 0.51574\n"," Accuracy = 81.63%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 1 / 461\n"," Loss = 0.32408\n"," Accuracy = 84.38%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 11 / 461\n"," Loss = 0.38825\n"," Accuracy = 84.66%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 21 / 461\n"," Loss = 0.38348\n"," Accuracy = 84.82%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 31 / 461\n"," Loss = 0.24264\n"," Accuracy = 86.09%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 41 / 461\n"," Loss = 0.46032\n"," Accuracy = 85.90%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 51 / 461\n"," Loss = 0.30685\n"," Accuracy = 85.97%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 61 / 461\n"," Loss = 0.50978\n"," Accuracy = 85.66%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 71 / 461\n"," Loss = 0.35120\n"," Accuracy = 85.70%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 81 / 461\n"," Loss = 0.22785\n"," Accuracy = 85.34%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 91 / 461\n"," Loss = 0.34468\n"," Accuracy = 84.96%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 101 / 461\n"," Loss = 0.20470\n"," Accuracy = 84.87%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 111 / 461\n"," Loss = 0.21797\n"," Accuracy = 84.85%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 121 / 461\n"," Loss = 0.43993\n"," Accuracy = 84.53%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 131 / 461\n"," Loss = 0.51987\n"," Accuracy = 84.52%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 141 / 461\n"," Loss = 0.30004\n"," Accuracy = 84.18%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 151 / 461\n"," Loss = 0.45806\n"," Accuracy = 83.98%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 161 / 461\n"," Loss = 0.38303\n"," Accuracy = 83.85%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 171 / 461\n"," Loss = 0.36306\n"," Accuracy = 83.95%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 181 / 461\n"," Loss = 0.38021\n"," Accuracy = 83.86%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 191 / 461\n"," Loss = 0.36978\n"," Accuracy = 83.93%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 201 / 461\n"," Loss = 0.33626\n"," Accuracy = 83.99%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 211 / 461\n"," Loss = 0.31914\n"," Accuracy = 84.03%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 221 / 461\n"," Loss = 0.37399\n"," Accuracy = 83.91%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 231 / 461\n"," Loss = 0.41464\n"," Accuracy = 84.08%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 241 / 461\n"," Loss = 0.33857\n"," Accuracy = 83.95%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 251 / 461\n"," Loss = 0.28509\n"," Accuracy = 83.98%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 261 / 461\n"," Loss = 0.33012\n"," Accuracy = 83.98%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 271 / 461\n"," Loss = 0.35652\n"," Accuracy = 83.87%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 281 / 461\n"," Loss = 0.26629\n"," Accuracy = 83.87%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 291 / 461\n"," Loss = 0.33316\n"," Accuracy = 83.97%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 301 / 461\n"," Loss = 0.34711\n"," Accuracy = 83.90%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 311 / 461\n"," Loss = 0.54246\n"," Accuracy = 83.87%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 321 / 461\n"," Loss = 0.38889\n"," Accuracy = 83.93%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 331 / 461\n"," Loss = 0.28257\n"," Accuracy = 83.95%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 341 / 461\n"," Loss = 0.27880\n"," Accuracy = 83.95%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 351 / 461\n"," Loss = 0.48657\n"," Accuracy = 83.93%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 361 / 461\n"," Loss = 0.25671\n"," Accuracy = 83.86%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 371 / 461\n"," Loss = 0.48498\n"," Accuracy = 83.84%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 381 / 461\n"," Loss = 0.28392\n"," Accuracy = 83.76%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 391 / 461\n"," Loss = 0.44739\n"," Accuracy = 83.62%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 401 / 461\n"," Loss = 0.64867\n"," Accuracy = 83.51%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 411 / 461\n"," Loss = 0.44090\n"," Accuracy = 83.38%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 421 / 461\n"," Loss = 0.44229\n"," Accuracy = 83.35%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 431 / 461\n"," Loss = 0.42065\n"," Accuracy = 83.35%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 441 / 461\n"," Loss = 0.46168\n"," Accuracy = 83.33%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 451 / 461\n"," Loss = 0.44537\n"," Accuracy = 83.29%\n","=========================\n","======== Metrics ========\n","[Epoch 8]\n"," Batch 461 / 461\n"," Loss = 0.37170\n"," Accuracy = 83.25%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 1 / 461\n"," Loss = 0.24089\n"," Accuracy = 90.62%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 11 / 461\n"," Loss = 0.33973\n"," Accuracy = 86.93%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 21 / 461\n"," Loss = 0.34317\n"," Accuracy = 87.80%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 31 / 461\n"," Loss = 0.48143\n"," Accuracy = 87.50%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 41 / 461\n"," Loss = 0.41888\n"," Accuracy = 87.27%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 51 / 461\n"," Loss = 0.36028\n"," Accuracy = 87.62%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 61 / 461\n"," Loss = 0.18762\n"," Accuracy = 87.81%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 71 / 461\n"," Loss = 0.24388\n"," Accuracy = 88.03%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 81 / 461\n"," Loss = 0.37215\n"," Accuracy = 87.58%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 91 / 461\n"," Loss = 0.35069\n"," Accuracy = 87.47%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 101 / 461\n"," Loss = 0.22322\n"," Accuracy = 87.65%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 111 / 461\n"," Loss = 0.27834\n"," Accuracy = 87.67%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 121 / 461\n"," Loss = 0.18556\n"," Accuracy = 87.60%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 131 / 461\n"," Loss = 0.46349\n"," Accuracy = 87.07%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 141 / 461\n"," Loss = 0.17478\n"," Accuracy = 87.15%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 151 / 461\n"," Loss = 0.36696\n"," Accuracy = 87.23%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 161 / 461\n"," Loss = 0.49793\n"," Accuracy = 87.15%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 171 / 461\n"," Loss = 0.27163\n"," Accuracy = 87.04%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 181 / 461\n"," Loss = 0.28226\n"," Accuracy = 86.93%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 191 / 461\n"," Loss = 0.36994\n"," Accuracy = 87.03%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 201 / 461\n"," Loss = 0.29669\n"," Accuracy = 86.88%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 211 / 461\n"," Loss = 0.22058\n"," Accuracy = 86.92%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 221 / 461\n"," Loss = 0.33672\n"," Accuracy = 86.84%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 231 / 461\n"," Loss = 0.32660\n"," Accuracy = 86.80%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 241 / 461\n"," Loss = 0.34211\n"," Accuracy = 86.72%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 251 / 461\n"," Loss = 0.37595\n"," Accuracy = 86.69%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 261 / 461\n"," Loss = 0.22626\n"," Accuracy = 86.67%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 271 / 461\n"," Loss = 0.38423\n"," Accuracy = 86.69%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 281 / 461\n"," Loss = 0.26189\n"," Accuracy = 86.71%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 291 / 461\n"," Loss = 0.27003\n"," Accuracy = 86.78%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 301 / 461\n"," Loss = 0.20130\n"," Accuracy = 86.75%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 311 / 461\n"," Loss = 0.42363\n"," Accuracy = 86.71%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 321 / 461\n"," Loss = 0.29435\n"," Accuracy = 86.58%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 331 / 461\n"," Loss = 0.28890\n"," Accuracy = 86.59%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 341 / 461\n"," Loss = 0.25091\n"," Accuracy = 86.46%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 351 / 461\n"," Loss = 0.43089\n"," Accuracy = 86.49%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 361 / 461\n"," Loss = 0.36332\n"," Accuracy = 86.46%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 371 / 461\n"," Loss = 0.37641\n"," Accuracy = 86.41%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 381 / 461\n"," Loss = 0.31932\n"," Accuracy = 86.49%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 391 / 461\n"," Loss = 0.30591\n"," Accuracy = 86.47%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 401 / 461\n"," Loss = 0.68647\n"," Accuracy = 86.37%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 411 / 461\n"," Loss = 0.28968\n"," Accuracy = 86.41%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 421 / 461\n"," Loss = 0.81066\n"," Accuracy = 86.33%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 431 / 461\n"," Loss = 0.26476\n"," Accuracy = 86.27%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 441 / 461\n"," Loss = 0.31818\n"," Accuracy = 86.26%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 451 / 461\n"," Loss = 0.38789\n"," Accuracy = 86.18%\n","=========================\n","======== Metrics ========\n","[Epoch 9]\n"," Batch 461 / 461\n"," Loss = 0.32225\n"," Accuracy = 86.22%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 1 / 461\n"," Loss = 0.20673\n"," Accuracy = 93.75%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 11 / 461\n"," Loss = 0.24277\n"," Accuracy = 90.62%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 21 / 461\n"," Loss = 0.22167\n"," Accuracy = 91.37%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 31 / 461\n"," Loss = 0.30524\n"," Accuracy = 90.93%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 41 / 461\n"," Loss = 0.20472\n"," Accuracy = 91.08%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 51 / 461\n"," Loss = 0.42902\n"," Accuracy = 90.13%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 61 / 461\n"," Loss = 0.24789\n"," Accuracy = 90.73%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 71 / 461\n"," Loss = 0.21761\n"," Accuracy = 90.49%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 81 / 461\n"," Loss = 0.34205\n"," Accuracy = 90.82%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 91 / 461\n"," Loss = 0.24049\n"," Accuracy = 90.80%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 101 / 461\n"," Loss = 0.31035\n"," Accuracy = 90.84%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 111 / 461\n"," Loss = 0.34232\n"," Accuracy = 90.62%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 121 / 461\n"," Loss = 0.13945\n"," Accuracy = 90.55%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 131 / 461\n"," Loss = 0.16025\n"," Accuracy = 90.43%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 141 / 461\n"," Loss = 0.18024\n"," Accuracy = 90.40%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 151 / 461\n"," Loss = 0.15316\n"," Accuracy = 90.40%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 161 / 461\n"," Loss = 0.39271\n"," Accuracy = 90.16%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 171 / 461\n"," Loss = 0.20580\n"," Accuracy = 90.13%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 181 / 461\n"," Loss = 0.24169\n"," Accuracy = 90.14%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 191 / 461\n"," Loss = 0.29156\n"," Accuracy = 90.10%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 201 / 461\n"," Loss = 0.24368\n"," Accuracy = 90.11%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 211 / 461\n"," Loss = 0.50474\n"," Accuracy = 89.91%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 221 / 461\n"," Loss = 0.33867\n"," Accuracy = 89.85%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 231 / 461\n"," Loss = 0.23971\n"," Accuracy = 89.84%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 241 / 461\n"," Loss = 0.13801\n"," Accuracy = 89.87%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 251 / 461\n"," Loss = 0.36554\n"," Accuracy = 89.69%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 261 / 461\n"," Loss = 0.43396\n"," Accuracy = 89.63%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 271 / 461\n"," Loss = 0.31179\n"," Accuracy = 89.64%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 281 / 461\n"," Loss = 0.22396\n"," Accuracy = 89.56%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 291 / 461\n"," Loss = 0.24327\n"," Accuracy = 89.39%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 301 / 461\n"," Loss = 0.25557\n"," Accuracy = 89.42%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 311 / 461\n"," Loss = 0.40461\n"," Accuracy = 89.32%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 321 / 461\n"," Loss = 0.21568\n"," Accuracy = 89.32%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 331 / 461\n"," Loss = 0.26900\n"," Accuracy = 89.27%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 341 / 461\n"," Loss = 0.21625\n"," Accuracy = 89.26%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 351 / 461\n"," Loss = 0.29369\n"," Accuracy = 89.18%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 361 / 461\n"," Loss = 0.17739\n"," Accuracy = 89.14%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 371 / 461\n"," Loss = 0.24826\n"," Accuracy = 89.04%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 381 / 461\n"," Loss = 0.26192\n"," Accuracy = 88.98%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 391 / 461\n"," Loss = 0.17194\n"," Accuracy = 88.98%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 401 / 461\n"," Loss = 0.36621\n"," Accuracy = 88.94%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 411 / 461\n"," Loss = 0.24113\n"," Accuracy = 88.88%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 421 / 461\n"," Loss = 0.43346\n"," Accuracy = 88.76%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 431 / 461\n"," Loss = 0.27305\n"," Accuracy = 88.78%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 441 / 461\n"," Loss = 0.16083\n"," Accuracy = 88.83%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 451 / 461\n"," Loss = 0.25778\n"," Accuracy = 88.79%\n","=========================\n","======== Metrics ========\n","[Epoch 10]\n"," Batch 461 / 461\n"," Loss = 0.23769\n"," Accuracy = 88.69%\n","=========================\n","Model is successfully trained\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"anS2dVSueTa-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622502755495,"user_tz":-480,"elapsed":478,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"760d76c0-0590-4ba9-9c09-b8dbed28b8f3"},"source":["# 3.5 Loading the cleaned dataset into the model training\n","with open(os.path.join(directory, 'CleanedDataset3'),'rb') as filehandler:\n","    untrusted_dataset = pickle.load(filehandler)\n","\n","# untrusted_dataloader = torch.utils.data.DataLoader(untrusted_dataset, batch_size=32, shuffle=True)\n","\n","# i = 0\n","# for index, images, labels in untrusted_dataloader:\n","#     print(str(i),'\\t\\t',images.shape)\n","#     print('\\t\\t',labels.shape)\n","#     print('\\t\\t',index.shape)\n","#     i += 1\n","\n","print('Dataset loaded successfully')"],"execution_count":142,"outputs":[{"output_type":"stream","text":["Dataset loaded successfully\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVX7PuIJOU7o","executionInfo":{"status":"ok","timestamp":1622512823374,"user_tz":-480,"elapsed":150436,"user":{"displayName":"Huey Tai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKys-aiPxCqLfmxee6wtkZjk-RLKMz2IijeKgTbw=s64","userId":"17865543125183085671"}},"outputId":"884d4861-6222-4992-e7de-7bc5c0fcb63b"},"source":["# 4. Testing phase\n","\n","for j in range(10):\n","\n","    # Load the model to be tested\n","    model_path = os.path.join(model_dir, 'Control_BinClassifier{}.pth'.format(j+1)) # Insert path of .pth file here\n","    model.load_state_dict(torch.load(model_path, map_location=device), )\n","    model = model.to(device)\n","    \n","    # Define loss function\n","    loss_func = nn.CrossEntropyLoss()\n","    acc = 0\n","\n","    print('Now testing {}...'.format(model_path))\n","\n","    for i, (images, labels) in enumerate(test_dataloader):\n","        \n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        logits = model(images)\n","\n","        loss = loss_func(logits, labels)\n","\n","        _, pred = torch.max(logits, 1)\n","        batch_acc = (labels == pred).sum().item() / images.shape[0] * 100\n","        acc = (batch_acc + acc * i) / (i + 1)\n","        \n","        if i == len(test_dataloader) - 1:\n","            print_metrics(1, i + 1, len(test_dataloader), loss.item(), acc)\n","\n","print('Models are successfully tested')"],"execution_count":162,"outputs":[{"output_type":"stream","text":["Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier1.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.54115\n"," Accuracy = 72.43%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier2.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 1.16385\n"," Accuracy = 71.99%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier3.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.44612\n"," Accuracy = 75.71%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier4.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.24130\n"," Accuracy = 74.96%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier5.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.43748\n"," Accuracy = 75.67%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier6.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.34509\n"," Accuracy = 75.67%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier7.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.60885\n"," Accuracy = 72.55%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier8.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.26481\n"," Accuracy = 75.20%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier9.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.06583\n"," Accuracy = 74.92%\n","=========================\n","Now testing /content/drive/MyDrive/Colab Notebooks/models/Control_BinClassifier10.pth...\n","======== Metrics ========\n","[Epoch 1]\n"," Batch 79 / 79\n"," Loss = 0.35900\n"," Accuracy = 72.90%\n","=========================\n","Models are successfully tested\n"],"name":"stdout"}]}]}